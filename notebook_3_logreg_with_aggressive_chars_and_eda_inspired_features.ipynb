{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ec51d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nikitabaramiya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, ConfusionMatrixDisplay\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "# from nltk.stem.snowball import SnowballStemmer\n",
    "# stemmer = SnowballStemmer(\"russian\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbdc1b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len('абвгдежзиклмнопрстухцчшщэюя')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd4ac925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xy_train_val.loc[Xy_train_val.target == '5', 'negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdcac75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [word if word.islower() else '' for word in word_tokenize(X_train_val.positive[0], 'russian')[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11e78858",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:870: UserWarning: unknown class(es) [','] will be ignored\n",
      "  warnings.warn(\n",
      "/var/folders/qr/s242yg692gj9d2qnn_jnhs900000gn/T/ipykernel_28214/3844871074.py:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  data['positive'] = data['positive'].str.replace(',', ', ').str.replace('.', '. ').apply(lambda x: re.sub(' +', ' ', x))\n",
      "/var/folders/qr/s242yg692gj9d2qnn_jnhs900000gn/T/ipykernel_28214/3844871074.py:17: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  data['negative'] = data['negative'].str.replace(',', ', ').str.replace('.', '. ').apply(lambda x: re.sub(' +', ' ', x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((50876, 25), (50876, 9), (50651, 25))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy_train_val = pd.read_csv('data/train.csv', index_col='review_id').fillna('Unknown')\n",
    "X_train_val, y_train_val = Xy_train_val.iloc[:, :-1], Xy_train_val.iloc[:, -1] # .apply(lambda x: int(x[0]))\n",
    "\n",
    "mb = MultiLabelBinarizer(classes=[str(i) for i in range(9)])\n",
    "y_train_val = mb.fit_transform(y_train_val)\n",
    "\n",
    "X_test = pd.read_csv('data/test.csv', index_col='review_id').fillna('Unknown')\n",
    "\n",
    "for data in [X_train_val, X_test]:\n",
    "    \n",
    "    # class 0: special symbol\n",
    "    data['xa_symbol_pos'] = (data['positive'].str.find('\\xa0') != -1).astype(int)\n",
    "    data['xa_symbol_neg'] = (data['negative'].str.find('\\xa0') != -1).astype(int)\n",
    "    \n",
    "    # small preprocessing\n",
    "    data['positive'] = data['positive'].str.replace(',', ', ').str.replace('.', '. ').apply(lambda x: re.sub(' +', ' ', x))\n",
    "    data['negative'] = data['negative'].str.replace(',', ', ').str.replace('.', '. ').apply(lambda x: re.sub(' +', ' ', x))\n",
    "    \n",
    "    # class 8: length (woith round -1)\n",
    "    data['length_pos'] = data['positive'].apply(lambda x: round(len(x), -1)) # .str.len() also works\n",
    "    data.loc[data['length_pos'] > 1000, 'length_pos'] = 1000\n",
    "    data['length_neg'] = data['negative'].apply(lambda x: round(len(x), -1))\n",
    "    data.loc[data['length_neg'] > 1000, 'length_neg'] = 1000\n",
    "    \n",
    "    # class \n",
    "    data['max_pos'] = data['positive'].apply(lambda x: np.max([len(w) for w in x.split(' ')]))\n",
    "    data.loc[data['max_pos'] > 25, 'max_pos'] = 25\n",
    "    data['max_neg'] = data['negative'].apply(lambda x: np.max([len(w) for w in x.split(' ')]))\n",
    "    data.loc[data['max_neg'] > 25, 'max_neg'] = 25\n",
    "    \n",
    "    #\n",
    "    data['most_common_pos'] = data['positive'].apply(\n",
    "        lambda x: Counter([w for w in x.split(' ')]).most_common(1)[0][1]\n",
    "    )\n",
    "    data.loc[data['most_common_pos'] > 25, 'most_common_pos'] = 25\n",
    "    data['most_common_neg'] = data['negative'].apply(\n",
    "        lambda x: Counter([w for w in x.split(' ')]).most_common(1)[0][1]\n",
    "    )\n",
    "    data.loc[data['most_common_neg'] > 25, 'most_common_neg'] = 25\n",
    "    \n",
    "    for col in ['city', 'position']:\n",
    "        counts = data[col].value_counts()\n",
    "        data.loc[data[col].isin(counts[counts < 5].index), col] = 'Прочее'\n",
    "        \n",
    "    cols = ['salary_rating', 'team_rating', 'managment_rating', \n",
    "            'career_rating', 'workplace_rating', 'rest_recovery_rating']\n",
    "    \n",
    "    for i in range(1, 5+1):\n",
    "        data[f'count_{i}'] = (data.loc[:, cols] == i).sum(axis=1)\n",
    "    \n",
    "#     rus_alph = 'абвгдежзиклмнопрстуфхцчшщэюя'.upper()\n",
    "#     initials = [i + '.' + j for i in rus_alph for j in rus_alph]\n",
    "    \n",
    "#     data['initials_pos'] = data['positive'].apply(lambda x: any(x.find(i) != -1 for i in initials))\n",
    "#     data['initials_neg'] = data['negative'].apply(lambda x: any(x.find(i) != -1 for i in initials))\n",
    "    \n",
    "    data['rating_mean'] = data.loc[:, cols].mean(axis=1)\n",
    "    data['rating_std'] = data.loc[:, cols].std(axis=1)\n",
    "    \n",
    "#     data['positive'] = data['positive'].apply(\n",
    "#         lambda x: re.sub(' +', ' ', ' '.join(\n",
    "#             [stemmer.stem(word) if word not in string.punctuation else '' for word in word_tokenize(x)]\n",
    "#         ))\n",
    "#     )\n",
    "#     data['negative'] = data['negative'].apply(\n",
    "#         lambda x: re.sub(' +', ' ', ' '.join(\n",
    "#             [stemmer.stem(word) if word not in string.punctuation else '' for word in word_tokenize(x)]\n",
    "#         ))\n",
    "#     )\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_val.shape, y_train_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e709063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyTransformer(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Mini class to return initial features without transformation\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, value=None):\n",
    "        TransformerMixin.__init__(self)\n",
    "        self.value = value\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {'value': self.value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aecf610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('transforms',\n",
       "                 ColumnTransformer(transformers=[('ohe',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  [0, 1, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                   11, 12, 13, 14, 15, 16, 17,\n",
       "                                                   18, 19, 20, 21, 22]),\n",
       "                                                 ('two_features',\n",
       "                                                  <__main__.DummyTransformer object at 0x7fcd91a50940>,\n",
       "                                                  [23, 24]),\n",
       "                                                 ('tfidf1',\n",
       "                                                  TfidfVectorizer(analyzer='char_wb',\n",
       "                                                                  max_df=0.999,\n",
       "                                                                  min_df=0.001,\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               4)),\n",
       "                                                  2),\n",
       "                                                 ('tfidf2',\n",
       "                                                  TfidfV...\n",
       "                                                                  min_df=0.001,\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               4)),\n",
       "                                                  3),\n",
       "                                                 ('count1',\n",
       "                                                  CountVectorizer(analyzer='char_wb',\n",
       "                                                                  binary=True,\n",
       "                                                                  max_df=0.999,\n",
       "                                                                  min_df=0.001,\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               4)),\n",
       "                                                  2),\n",
       "                                                 ('count2',\n",
       "                                                  CountVectorizer(analyzer='char_wb',\n",
       "                                                                  binary=True,\n",
       "                                                                  max_df=0.999,\n",
       "                                                                  min_df=0.001,\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               4)),\n",
       "                                                  3)])),\n",
       "                ('lr',\n",
       "                 OneVsRestClassifier(estimator=LogisticRegression(C=0.01,\n",
       "                                                                  max_iter=500,\n",
       "                                                                  n_jobs=-1,\n",
       "                                                                  random_state=42)))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('transforms', ColumnTransformer([\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore'), [0, 1] + [*range(4, X_val.shape[1]-2)]),\n",
    "        ('two_features', DummyTransformer(), [X_val.shape[1]-2, X_val.shape[1]-1]),\n",
    "        ('tfidf1', TfidfVectorizer(ngram_range=(1, 4), max_df=0.999, min_df=0.001, \n",
    "                                   analyzer='char_wb'), 2),\n",
    "        ('tfidf2', TfidfVectorizer(ngram_range=(1, 4), max_df=0.999, min_df=0.001, \n",
    "                                   analyzer='char_wb'), 3),\n",
    "        ('count1', CountVectorizer(ngram_range=(1, 4), max_df=0.999, min_df=0.001, binary=True,\n",
    "                                   analyzer='char_wb'), 2),\n",
    "        ('count2', CountVectorizer(ngram_range=(1, 4), max_df=0.999, min_df=0.001, binary=True,\n",
    "                                   analyzer='char_wb'), 3),\n",
    "    ])),\n",
    "    ('lr', OneVsRestClassifier(LogisticRegression(C=0.01, max_iter=500, n_jobs=-1, random_state=42)))\n",
    "])\n",
    "pipeline.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65a6d445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_18022022']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipeline, 'model_18022022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49af4460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multilabel(model, X):\n",
    "    y_pred = list(map(lambda x: ','.join(x), mb.inverse_transform(model.predict(X))))\n",
    "    y_pred_top1 = model.predict_proba(X).argmax(axis=1)\n",
    "    \n",
    "    return np.where([len(x) > 0 for x in y_pred], y_pred, y_pred_top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1cb39e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = joblib.load('model_18022022')\n",
    "\n",
    "pd.DataFrame({\n",
    "    'review_id': X_test.index, \n",
    "    'target': predict_multilabel(model, X_test) # model.predict(X_test).flatten()\n",
    "}).to_csv('answers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf96c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.811\n",
    "# Pipeline(steps=[('transforms',\n",
    "#                  ColumnTransformer(transformers=[('ohe',\n",
    "#                                                   OneHotEncoder(handle_unknown='ignore'),\n",
    "#                                                   [0, 1, 4, 5, 6, 7, 8, 9, 10,\n",
    "#                                                    11, 12, 13, 14, 15, 16, 17,\n",
    "#                                                    18, 19, 20, 21, 22]),\n",
    "#                                                  ('two_features',\n",
    "#                                                   <__main__.DummyTransformer object at 0x7fcd91a50940>,\n",
    "#                                                   [23, 24]),\n",
    "#                                                  ('tfidf1',\n",
    "#                                                   TfidfVectorizer(analyzer='char_wb',\n",
    "#                                                                   max_df=0.999,\n",
    "#                                                                   min_df=0.001,\n",
    "#                                                                   ngram_range=(1,\n",
    "#                                                                                4)),\n",
    "#                                                   2),\n",
    "#                                                  ('tfidf2',\n",
    "#                                                   TfidfV...\n",
    "#                                                                   min_df=0.001,\n",
    "#                                                                   ngram_range=(1,\n",
    "#                                                                                4)),\n",
    "#                                                   3),\n",
    "#                                                  ('count1',\n",
    "#                                                   CountVectorizer(analyzer='char_wb',\n",
    "#                                                                   binary=True,\n",
    "#                                                                   max_df=0.999,\n",
    "#                                                                   min_df=0.001,\n",
    "#                                                                   ngram_range=(1,\n",
    "#                                                                                4)),\n",
    "#                                                   2),\n",
    "#                                                  ('count2',\n",
    "#                                                   CountVectorizer(analyzer='char_wb',\n",
    "#                                                                   binary=True,\n",
    "#                                                                   max_df=0.999,\n",
    "#                                                                   min_df=0.001,\n",
    "#                                                                   ngram_range=(1,\n",
    "#                                                                                4)),\n",
    "#                                                   3)])),\n",
    "#                 ('lr',\n",
    "#                  OneVsRestClassifier(estimator=LogisticRegression(C=0.01,\n",
    "#                                                                   max_iter=500,\n",
    "#                                                                   n_jobs=-1,\n",
    "#                                                                   random_state=42)))])\n",
    "# 0.769645557967"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
