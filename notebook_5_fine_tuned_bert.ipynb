{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T08:25:55.917954Z",
     "iopub.status.busy": "2022-02-19T08:25:55.917627Z",
     "iopub.status.idle": "2022-02-19T08:26:04.898228Z",
     "shell.execute_reply": "2022-02-19T08:26:04.897413Z",
     "shell.execute_reply.started": "2022-02-19T08:25:55.917865Z"
    },
    "id": "R1txCOpKDuSW",
    "outputId": "245244f0-1d5e-4de0-cef2-4296008ff6a4"
   },
   "outputs": [],
   "source": [
    "# !pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T08:26:30.535536Z",
     "iopub.status.busy": "2022-02-19T08:26:30.534894Z",
     "iopub.status.idle": "2022-02-19T08:26:36.647487Z",
     "shell.execute_reply": "2022-02-19T08:26:36.646465Z",
     "shell.execute_reply.started": "2022-02-19T08:26:30.535496Z"
    },
    "id": "5ec51d6c",
    "outputId": "525307fa-4090-428f-c6e2-895787e6bd8f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer, FeatureExtractionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T08:26:36.654958Z",
     "iopub.status.busy": "2022-02-19T08:26:36.652867Z",
     "iopub.status.idle": "2022-02-19T08:26:36.718330Z",
     "shell.execute_reply": "2022-02-19T08:26:36.717466Z",
     "shell.execute_reply.started": "2022-02-19T08:26:36.654916Z"
    },
    "id": "c9325a86",
    "outputId": "5d9dbb76-e76e-4f48-eaa4-dde4efc6dc80",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T08:26:36.724079Z",
     "iopub.status.busy": "2022-02-19T08:26:36.722192Z",
     "iopub.status.idle": "2022-02-19T08:26:36.931217Z",
     "shell.execute_reply": "2022-02-19T08:26:36.930190Z",
     "shell.execute_reply.started": "2022-02-19T08:26:36.724040Z"
    },
    "id": "857f8f8f"
   },
   "outputs": [],
   "source": [
    "def cleanup():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T08:27:51.655294Z",
     "iopub.status.busy": "2022-02-19T08:27:51.654495Z",
     "iopub.status.idle": "2022-02-19T08:28:24.183862Z",
     "shell.execute_reply": "2022-02-19T08:28:24.182875Z",
     "shell.execute_reply.started": "2022-02-19T08:27:51.655246Z"
    },
    "id": "cd8b0c57",
    "outputId": "c402060c-40a5-4d8c-ab0e-499a95b3f975"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6373f453e9b34982a8105f8fc2d665b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=24.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f4f88ef4c74fc097a3bce2e1117481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=642.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea26fedf98984ee2848a9fa061a2bc93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1649718.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae269fd987de46548488d0ed22e12938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e19aa7309e14a6fbcff6c855829dff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=711456784.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-sentence and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model = 'DeepPavlov/rubert-base-cased-sentence' # 0.780006575919\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    base_model, num_labels=9, problem_type='multi_label_classification'\n",
    ").to(device)\n",
    "# torch.save(model.state_dict(), 'model_bert_pavlov_initial.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T08:28:39.354195Z",
     "iopub.status.busy": "2022-02-19T08:28:39.353504Z",
     "iopub.status.idle": "2022-02-19T08:28:42.148968Z",
     "shell.execute_reply": "2022-02-19T08:28:42.148183Z",
     "shell.execute_reply.started": "2022-02-19T08:28:39.354158Z"
    },
    "id": "11e78858",
    "outputId": "bfbeffcd-54f1-49e6-bcc9-dfc2f0ec05e5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:870: UserWarning: unknown class(es) [','] will be ignored\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((50367,), (509,), (50367, 9), (509, 9), (50651,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy_train_val = pd.read_csv('data/train.csv', index_col='review_id').fillna('Нет информации.')\n",
    "X_train_val, y_train_val = Xy_train_val.iloc[:, :-1], Xy_train_val.iloc[:, -1]\n",
    "\n",
    "mb = MultiLabelBinarizer(classes=[str(i) for i in range(9)])\n",
    "y_train_val = mb.fit_transform(y_train_val)\n",
    "\n",
    "X_test = pd.read_csv('data/test.csv', index_col='review_id').fillna('Нет информации.')\n",
    "\n",
    "# for data in [X_train_val, X_test]:\n",
    "#     data.positive = data.positive.apply(lambda x: \"Короткое предложение. \" if len(x) < 50 else \"\") + data.positive\n",
    "#     data.negative = data.negative.apply(lambda x: \"Короткое предложение. \" if len(x) < 50 else \"\") + data.negative\n",
    "\n",
    "X_train_val = X_train_val.iloc[:, 2:4].apply(lambda row: '. '.join(row.values.astype(str)), axis=1).values\n",
    "X_test = X_test.iloc[:, 2:4].apply(lambda row: '. '.join(row.values.astype(str)), axis=1).values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.01, random_state=42)\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T08:28:42.150850Z",
     "iopub.status.busy": "2022-02-19T08:28:42.150583Z",
     "iopub.status.idle": "2022-02-19T08:28:42.158663Z",
     "shell.execute_reply": "2022-02-19T08:28:42.157746Z",
     "shell.execute_reply.started": "2022-02-19T08:28:42.150815Z"
    },
    "id": "44acd603"
   },
   "outputs": [],
   "source": [
    "class MyDatasetForClassification(Dataset):\n",
    "    \"\"\"\n",
    "    Make Dataset instance to return item for classification models\n",
    "    \n",
    "    Args:\n",
    "    - X: n x 1\n",
    "    - y: n x 9\n",
    "    - tokenizer: tokenize sentences (to get 'input_ids' and 'attention_mask')\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y=None, tokenizer=None):\n",
    "        self.sentences = list(X)\n",
    "        self.labels = torch.FloatTensor(y) if y is not None else torch.zeros((len(self.sentences), 9))\n",
    "        \n",
    "        self.tokenizer_outputs = tokenizer.batch_encode_plus(self.sentences, return_tensors=\"pt\", \n",
    "                                                             max_length=128, padding=True, truncation=True)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_ids = self.tokenizer_outputs['input_ids'][index]\n",
    "        attention_mask = self.tokenizer_outputs['attention_mask'][index]\n",
    "\n",
    "        label = self.labels[index]\n",
    "\n",
    "        return {'attention_mask': attention_mask, \n",
    "                'input_ids': input_ids, \n",
    "                'labels': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T08:28:55.308338Z",
     "iopub.status.busy": "2022-02-19T08:28:55.308070Z",
     "iopub.status.idle": "2022-02-19T08:29:19.726338Z",
     "shell.execute_reply": "2022-02-19T08:29:19.725607Z",
     "shell.execute_reply.started": "2022-02-19T08:28:55.308309Z"
    },
    "id": "b47dca60"
   },
   "outputs": [],
   "source": [
    "dataset_train = MyDatasetForClassification(X_train, y_train, tokenizer)\n",
    "dataset_val = MyDatasetForClassification(X_val, y_val, tokenizer)\n",
    "dataset_test = MyDatasetForClassification(X_test, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T08:29:19.728249Z",
     "iopub.status.busy": "2022-02-19T08:29:19.727993Z",
     "iopub.status.idle": "2022-02-19T08:29:19.734037Z",
     "shell.execute_reply": "2022-02-19T08:29:19.733106Z",
     "shell.execute_reply.started": "2022-02-19T08:29:19.728215Z"
    },
    "id": "5c6f20ae"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    cleanup()\n",
    "    \n",
    "    y_pred, y_true = eval_preds\n",
    "    \n",
    "    if type(y_pred) == tuple:\n",
    "        y_pred = y_pred[0]\n",
    "    \n",
    "    z = 1 / (1 + np.exp(-y_pred))\n",
    "    y_pred, y_true = np.array(z >= 0.5, dtype=int), y_true.astype(int)\n",
    "    \n",
    "    return {'f1_score': f1_score(y_true, y_pred, average='samples')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_hidden_states = model(**dataset_test[:2], output_hidden_states=True)['hidden_states'][0].mean(dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_hidden_states[0].mean(dim=1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = FeatureExtractionPipeline(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.2061765193939209,\n",
       "  0.2131747305393219,\n",
       "  -0.005690824240446091,\n",
       "  -0.03178182244300842,\n",
       "  0.07467031478881836,\n",
       "  -0.0338858962059021,\n",
       "  -0.06764063239097595,\n",
       "  -0.013200432062149048,\n",
       "  -0.07935985177755356]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline('Нет информации')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T08:40:18.342335Z",
     "iopub.status.busy": "2022-02-19T08:40:18.342077Z"
    },
    "id": "8f9470ac"
   },
   "outputs": [],
   "source": [
    "cleanup()\n",
    "\n",
    "for lr in [5e-6, 1e-5, 5e-5]:\n",
    "    for ws in [0, 500, 1000]:\n",
    "        for bs in [16, 32]:\n",
    "            print(lr, ws, bs)\n",
    "            \n",
    "            model.load_state_dict(torch.load('model_bert_pavlov_initial.pt', map_location=device))\n",
    "            \n",
    "            training_args = TrainingArguments(\n",
    "                output_dir=\"test_trainer\",\n",
    "                per_device_train_batch_size=bs,\n",
    "                per_device_eval_batch_size=32,\n",
    "                num_train_epochs=2,\n",
    "                warmup_steps=ws,\n",
    "                learning_rate=lr,\n",
    "                evaluation_strategy=\"epoch\",\n",
    "                eval_accumulation_steps=10,\n",
    "                save_strategy='epoch',\n",
    "                load_best_model_at_end=True,\n",
    "                metric_for_best_model='f1_score',\n",
    "                seed=42,\n",
    "            )\n",
    "            \n",
    "            trainer = Trainer(model=model, \n",
    "                              args=training_args, \n",
    "                              train_dataset=dataset_train, \n",
    "                              eval_dataset=dataset_val, \n",
    "                              compute_metrics=compute_metrics)\n",
    "            \n",
    "            trainer.train()\n",
    "            \n",
    "            torch.save(model.state_dict(), f'model_bert_pavlov_{lr}_{ws}_{bs}.pt')\n",
    "            \n",
    "            cleanup()\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T21:28:16.860385Z",
     "iopub.status.busy": "2022-02-18T21:28:16.859472Z",
     "iopub.status.idle": "2022-02-18T21:28:16.867061Z",
     "shell.execute_reply": "2022-02-18T21:28:16.866125Z",
     "shell.execute_reply.started": "2022-02-18T21:28:16.860300Z"
    },
    "id": "UvTfqYMyosg9"
   },
   "outputs": [],
   "source": [
    "# length = 128, epochs=3, warm=500, batch 32, 2-4 ---------> best\n",
    "# Epoch\tTraining Loss\tValidation Loss\tF1 Score\n",
    "# 1\t0.147500\t0.114881\t0.799581\n",
    "# 2\t0.107300\t0.108582\t0.814714\n",
    "# 3\t0.095200\t0.108814\t0.818717\n",
    "\n",
    "# length = 128 (64, 100), epochs=3 (5), warm=500 (1000), batch 32 (64), 2-4 + length feauture adding () -> 0.765064772802\n",
    "# Epoch\tTraining Loss\tValidation Loss\tF1 Score\n",
    "# 1\t0.148700\t0.116537\t0.802542\n",
    "# 2\t0.107600\t0.108154\t0.815998\n",
    "# 3\t0.095300\t0.108450\t0.822058\n",
    "\n",
    "# new length = 128, epochs=3, warm=500 + new 'unknown' filling + Pavlov\n",
    "# Epoch\tTraining Loss\tValidation Loss\tF1 Score\n",
    "# 1\t0.116400\t0.086875\t0.847000\n",
    "# 2\t0.092300\t0.083631\t0.863333\n",
    "# 3\t0.073400\t0.089647\t0.850667\n",
    "\n",
    "# new length = 128, epochs=3, warm=1000 + new 'unknown' filling + Pavlov + more data\n",
    "# Epoch\tTraining Loss\tValidation Loss\tF1 Score\n",
    "# 1\t0.111700\t0.088201\t0.840864\n",
    "# 2\t0.092700\t0.084430\t0.845776\n",
    "# 3\t0.072400\t0.089046\t0.847741\n",
    "\n",
    "# new length = 128, epochs=2, warm=1000 + new 'unknown' filling + length feauture adding () + Pavlov + more data\n",
    "# Epoch\tTraining Loss\tValidation Loss\tF1 Score\n",
    "# 1\t0.109400\t0.086877\t0.849378\n",
    "# 2\t0.090400\t0.081575\t0.864113\n",
    "\n",
    "# base pavlov\n",
    "# Epoch\tTraining Loss\tValidation Loss\tF1 Score\n",
    "# 1\t0.104400\t0.081640\t0.861166\n",
    "# 2\t0.085200\t0.079099\t0.865095\n",
    "# 3\t0.060600\t0.084978\t0.861100\n",
    "\n",
    "# no distill pavlov base-cased-sentence\n",
    "# Epoch\tTraining Loss\tValidation Loss\tF1 Score\n",
    "# 1\t0.109600\t0.084530\t0.869352\n",
    "# 2\t0.087800\t0.078737\t0.865422\n",
    "# 3\t0.064400\t0.079970\t0.862083\n",
    "\n",
    "# no distill pavlov base-cased\n",
    "# Epoch\tTraining Loss\tValidation Loss\tF1 Score\n",
    "# 1\t0.109400\t0.085003\t0.859201\n",
    "# 2\t0.089000\t0.082281\t0.865750\n",
    "# 3\t0.066100\t0.086777\t0.859528\n",
    "\n",
    "# no distill pavlov base-cased-sentence 1e-5\n",
    "# Epoch\tTraining Loss\tValidation Loss\tF1 Score\n",
    "# 1\t0.116600\t0.093780\t0.852980\n",
    "# 2\t0.099900\t0.084599\t0.868697\n",
    "# 3\t0.088200\t0.085746\t0.856909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T22:06:49.788577Z",
     "iopub.status.busy": "2022-02-18T22:06:49.788177Z",
     "iopub.status.idle": "2022-02-18T22:06:51.991898Z",
     "shell.execute_reply": "2022-02-18T22:06:51.991020Z",
     "shell.execute_reply.started": "2022-02-18T22:06:49.788535Z"
    },
    "id": "RhcW7RIYiHp4",
    "outputId": "8a1c12fc-6b22-4c37-bf25-171197076847"
   },
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "torch.save(model.state_dict(), 'model_bert_pavlov_full.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T22:00:22.708613Z",
     "iopub.status.busy": "2022-02-18T22:00:22.708317Z",
     "iopub.status.idle": "2022-02-18T22:00:22.716750Z",
     "shell.execute_reply": "2022-02-18T22:00:22.715675Z",
     "shell.execute_reply.started": "2022-02-18T22:00:22.708575Z"
    },
    "id": "5877ccf7"
   },
   "outputs": [],
   "source": [
    "def predict_multilabel_bert(model, X, thres=0.5):\n",
    "    model.to(device)\n",
    "    output = torch.sigmoid(model(**{k: v.to(device) for k, v in X.items()}).logits.detach().cpu())\n",
    "    \n",
    "    y_pred = list(map(lambda x: ','.join(x), mb.inverse_transform((output >= thres).long())))\n",
    "    y_pred_top1 = output.argmax(axis=1)\n",
    "    \n",
    "    return np.where([len(x) > 0 for x in y_pred], y_pred, y_pred_top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T22:00:22.719591Z",
     "iopub.status.busy": "2022-02-18T22:00:22.718486Z",
     "iopub.status.idle": "2022-02-18T22:03:34.434913Z",
     "shell.execute_reply": "2022-02-18T22:03:34.434212Z",
     "shell.execute_reply.started": "2022-02-18T22:00:22.719549Z"
    },
    "id": "tLWRFTXoM_Ix",
    "outputId": "ba97541a-7ba4-46d9-c08c-2bc491fbb7b0"
   },
   "outputs": [],
   "source": [
    "dataloader_test = DataLoader(dataset_test, batch_size=64, shuffle=False)\n",
    "\n",
    "pred_labels = []\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(dataloader_test):\n",
    "        pred_labels.append(predict_multilabel_bert(model, batch, thres=0.5))\n",
    "\n",
    "pred_labels = np.concatenate(pred_labels, axis=0)\n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T22:03:34.436924Z",
     "iopub.status.busy": "2022-02-18T22:03:34.436238Z",
     "iopub.status.idle": "2022-02-18T22:03:34.911400Z",
     "shell.execute_reply": "2022-02-18T22:03:34.910553Z",
     "shell.execute_reply.started": "2022-02-18T22:03:34.436879Z"
    },
    "id": "d1cb39e5"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'review_id': pd.read_csv('../input/headhunter/data/test.csv', index_col='review_id').index, \n",
    "    'target': pred_labels\n",
    "}).to_csv('answers2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jmhxa-Xobnag"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
