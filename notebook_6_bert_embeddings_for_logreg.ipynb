{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-20T07:28:55.144565Z",
     "iopub.status.idle": "2022-02-20T07:28:55.145639Z",
     "shell.execute_reply": "2022-02-20T07:28:55.145424Z",
     "shell.execute_reply.started": "2022-02-20T07:28:55.145398Z"
    },
    "id": "R1txCOpKDuSW",
    "outputId": "245244f0-1d5e-4de0-cef2-4296008ff6a4"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T07:28:55.150873Z",
     "iopub.status.busy": "2022-02-20T07:28:55.150677Z",
     "iopub.status.idle": "2022-02-20T07:29:01.717661Z",
     "shell.execute_reply": "2022-02-20T07:29:01.716843Z",
     "shell.execute_reply.started": "2022-02-20T07:28:55.150850Z"
    },
    "id": "5ec51d6c",
    "outputId": "525307fa-4090-428f-c6e2-895787e6bd8f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T07:29:01.719716Z",
     "iopub.status.busy": "2022-02-20T07:29:01.719479Z",
     "iopub.status.idle": "2022-02-20T07:29:01.772285Z",
     "shell.execute_reply": "2022-02-20T07:29:01.771573Z",
     "shell.execute_reply.started": "2022-02-20T07:29:01.719682Z"
    },
    "id": "c9325a86",
    "outputId": "5d9dbb76-e76e-4f48-eaa4-dde4efc6dc80",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T07:29:01.774232Z",
     "iopub.status.busy": "2022-02-20T07:29:01.773517Z",
     "iopub.status.idle": "2022-02-20T07:29:01.959028Z",
     "shell.execute_reply": "2022-02-20T07:29:01.958000Z",
     "shell.execute_reply.started": "2022-02-20T07:29:01.774150Z"
    },
    "id": "857f8f8f"
   },
   "outputs": [],
   "source": [
    "def cleanup():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T07:29:01.961778Z",
     "iopub.status.busy": "2022-02-20T07:29:01.961477Z",
     "iopub.status.idle": "2022-02-20T07:33:48.525169Z",
     "shell.execute_reply": "2022-02-20T07:33:48.524272Z",
     "shell.execute_reply.started": "2022-02-20T07:29:01.961741Z"
    },
    "id": "cd8b0c57",
    "outputId": "c402060c-40a5-4d8c-ab0e-499a95b3f975"
   },
   "outputs": [],
   "source": [
    "base_model = 'DeepPavlov/rubert-base-cased-sentence' # 0.780006575919\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    base_model, num_labels=9, problem_type='multi_label_classification'\n",
    ").to(device)\n",
    "torch.save(model.state_dict(), 'model_bert_pavlov_initial.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T07:33:48.527505Z",
     "iopub.status.busy": "2022-02-20T07:33:48.527065Z",
     "iopub.status.idle": "2022-02-20T07:33:51.523653Z",
     "shell.execute_reply": "2022-02-20T07:33:51.522991Z",
     "shell.execute_reply.started": "2022-02-20T07:33:48.527461Z"
    },
    "id": "11e78858",
    "outputId": "bfbeffcd-54f1-49e6-bcc9-dfc2f0ec05e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xy_train_val = pd.read_csv('../input/headhunter/data/data/train.csv', index_col='review_id').fillna('Нет информации.')\n",
    "X_train_val, y_train_val = Xy_train_val.iloc[:, :-1], Xy_train_val.iloc[:, -1]\n",
    "\n",
    "mb = MultiLabelBinarizer(classes=[str(i) for i in range(9)])\n",
    "y_train_val = mb.fit_transform(y_train_val)\n",
    "\n",
    "X_test = pd.read_csv('../input/headhunter/data/data/test.csv', index_col='review_id').fillna('Нет информации.')\n",
    "\n",
    "X_train_val = X_train_val.iloc[:, 2:4].apply(lambda row: '. '.join(row.values.astype(str)), axis=1).values\n",
    "X_test = X_test.iloc[:, 2:4].apply(lambda row: '. '.join(row.values.astype(str)), axis=1).values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.01, random_state=42)\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T07:33:51.525918Z",
     "iopub.status.busy": "2022-02-20T07:33:51.525658Z",
     "iopub.status.idle": "2022-02-20T07:33:51.532957Z",
     "shell.execute_reply": "2022-02-20T07:33:51.532271Z",
     "shell.execute_reply.started": "2022-02-20T07:33:51.525883Z"
    },
    "id": "44acd603"
   },
   "outputs": [],
   "source": [
    "class MyDatasetForClassification(Dataset):\n",
    "    \"\"\"\n",
    "    Make Dataset instance to return item for classification models\n",
    "    \n",
    "    Args:\n",
    "    - X: n x 1\n",
    "    - y: n x 9\n",
    "    - tokenizer: tokenize sentences (to get 'input_ids' and 'attention_mask')\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y=None, tokenizer=None):\n",
    "        self.sentences = list(X)\n",
    "        self.labels = torch.FloatTensor(y) if y is not None else torch.zeros((len(self.sentences), 9))\n",
    "        \n",
    "        self.tokenizer_outputs = tokenizer.batch_encode_plus(self.sentences, return_tensors=\"pt\", \n",
    "                                                             max_length=128, padding=True, truncation=True)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_ids = self.tokenizer_outputs['input_ids'][index]\n",
    "        attention_mask = self.tokenizer_outputs['attention_mask'][index]\n",
    "\n",
    "        label = self.labels[index]\n",
    "\n",
    "        return {'attention_mask': attention_mask, \n",
    "                'input_ids': input_ids, \n",
    "                'labels': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T07:33:51.534586Z",
     "iopub.status.busy": "2022-02-20T07:33:51.534155Z",
     "iopub.status.idle": "2022-02-20T07:34:16.255492Z",
     "shell.execute_reply": "2022-02-20T07:34:16.254705Z",
     "shell.execute_reply.started": "2022-02-20T07:33:51.534553Z"
    },
    "id": "b47dca60"
   },
   "outputs": [],
   "source": [
    "dataset_train = MyDatasetForClassification(X_train, y_train, tokenizer)\n",
    "dataset_val = MyDatasetForClassification(X_val, y_val, tokenizer)\n",
    "dataset_test = MyDatasetForClassification(X_test, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T07:34:16.257164Z",
     "iopub.status.busy": "2022-02-20T07:34:16.256921Z",
     "iopub.status.idle": "2022-02-20T07:34:16.262625Z",
     "shell.execute_reply": "2022-02-20T07:34:16.261896Z",
     "shell.execute_reply.started": "2022-02-20T07:34:16.257129Z"
    },
    "id": "5c6f20ae"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    cleanup()\n",
    "    \n",
    "    y_pred, y_true = eval_preds\n",
    "    \n",
    "    if type(y_pred) == tuple:\n",
    "        y_pred = y_pred[0]\n",
    "    \n",
    "    z = 1 / (1 + np.exp(-y_pred))\n",
    "    y_pred, y_true = np.array(z >= 0.5, dtype=int), y_true.astype(int)\n",
    "    \n",
    "    return {'f1_score': f1_score(y_true, y_pred, average='samples')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T07:36:07.983366Z",
     "iopub.status.busy": "2022-02-20T07:36:07.982519Z",
     "iopub.status.idle": "2022-02-20T09:14:14.016002Z",
     "shell.execute_reply": "2022-02-20T09:14:14.014355Z",
     "shell.execute_reply.started": "2022-02-20T07:36:07.983317Z"
    },
    "id": "8f9470ac"
   },
   "outputs": [],
   "source": [
    "cleanup()\n",
    "\n",
    "for lr in [5e-6, 1e-5]:\n",
    "    for ws, bs in [(1000, 16)]: #[(500, 32), (1000, 16)]:\n",
    "        for wd in [0, 1e-5]:\n",
    "            print(lr, ws, bs, wd)\n",
    "            \n",
    "            model.load_state_dict(torch.load('model_bert_pavlov_initial.pt', map_location=device))\n",
    "\n",
    "            training_args = TrainingArguments(\n",
    "                output_dir=\"test_trainer\",\n",
    "                per_device_train_batch_size=bs,\n",
    "                per_device_eval_batch_size=32,\n",
    "                num_train_epochs=2,\n",
    "                warmup_steps=ws,\n",
    "                learning_rate=lr,\n",
    "                weight_decay=wd,\n",
    "                evaluation_strategy=\"epoch\",\n",
    "                eval_accumulation_steps=10,\n",
    "                save_strategy='epoch',\n",
    "                load_best_model_at_end=True,\n",
    "                metric_for_best_model='f1_score',\n",
    "                seed=42,\n",
    "            )\n",
    "\n",
    "            trainer = Trainer(model=model, \n",
    "                              args=training_args, \n",
    "                              train_dataset=dataset_train, \n",
    "                              eval_dataset=dataset_val, \n",
    "                              compute_metrics=compute_metrics)\n",
    "\n",
    "            trainer.train()\n",
    "\n",
    "            torch.save(model.state_dict(), f'model_bert_pavlov_{lr}_{ws}_{bs}_{wd}.pt')\n",
    "\n",
    "            cleanup()\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T09:24:27.444103Z",
     "iopub.status.busy": "2022-02-20T09:24:27.443167Z",
     "iopub.status.idle": "2022-02-20T10:00:56.609025Z",
     "shell.execute_reply": "2022-02-20T10:00:56.608255Z",
     "shell.execute_reply.started": "2022-02-20T09:24:27.444062Z"
    },
    "id": "RhcW7RIYiHp4",
    "outputId": "8a1c12fc-6b22-4c37-bf25-171197076847"
   },
   "outputs": [],
   "source": [
    "cleanup()\n",
    "\n",
    "model.load_state_dict(torch.load('model_bert_pavlov_initial.pt', map_location=device))\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",\n",
    "    per_device_train_batch_size=16, #\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3, # \n",
    "    warmup_steps=1000, #\n",
    "    learning_rate=1e-5, #\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    eval_accumulation_steps=10,\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=False,\n",
    "    metric_for_best_model='f1_score',\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model, \n",
    "                  args=training_args, \n",
    "                  train_dataset=dataset_train, \n",
    "                  eval_dataset=dataset_val, \n",
    "                  compute_metrics=compute_metrics)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "torch.save(model.state_dict(), 'model_bert_pavlov_final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T12:55:14.771871Z",
     "iopub.status.busy": "2022-02-19T12:55:14.771520Z",
     "iopub.status.idle": "2022-02-19T12:55:17.505851Z",
     "shell.execute_reply": "2022-02-19T12:55:17.505093Z",
     "shell.execute_reply.started": "2022-02-19T12:55:14.771832Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('model_bert_pavlov_5e-06_1000_16.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:05:18.123207Z",
     "iopub.status.busy": "2022-02-19T21:05:18.122940Z",
     "iopub.status.idle": "2022-02-19T21:05:18.129482Z",
     "shell.execute_reply": "2022-02-19T21:05:18.128829Z",
     "shell.execute_reply.started": "2022-02-19T21:05:18.123172Z"
    },
    "id": "5877ccf7"
   },
   "outputs": [],
   "source": [
    "def predict_multilabel_bert(model, X, thres=0.5):\n",
    "    model.to(device)\n",
    "    output = torch.sigmoid(model(**{k: v.to(device) for k, v in X.items()}).logits.detach().cpu())\n",
    "    \n",
    "    y_pred = list(map(lambda x: ','.join(x), mb.inverse_transform((output >= thres).long())))\n",
    "    y_pred_top1 = output.argmax(axis=1)\n",
    "    \n",
    "    return np.where([len(x) > 0 for x in y_pred], y_pred, y_pred_top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:05:18.131284Z",
     "iopub.status.busy": "2022-02-19T21:05:18.130829Z",
     "iopub.status.idle": "2022-02-19T21:08:29.680687Z",
     "shell.execute_reply": "2022-02-19T21:08:29.679893Z",
     "shell.execute_reply.started": "2022-02-19T21:05:18.131248Z"
    },
    "id": "tLWRFTXoM_Ix",
    "outputId": "ba97541a-7ba4-46d9-c08c-2bc491fbb7b0"
   },
   "outputs": [],
   "source": [
    "dataloader_test = DataLoader(dataset_test, batch_size=64, shuffle=False)\n",
    "\n",
    "pred_labels = []\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(dataloader_test):\n",
    "        pred_labels.append(predict_multilabel_bert(model, batch, thres=0.5))\n",
    "\n",
    "pred_labels = np.concatenate(pred_labels, axis=0)\n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:08:29.683111Z",
     "iopub.status.busy": "2022-02-19T21:08:29.682818Z",
     "iopub.status.idle": "2022-02-19T21:08:30.166960Z",
     "shell.execute_reply": "2022-02-19T21:08:30.166192Z",
     "shell.execute_reply.started": "2022-02-19T21:08:29.683074Z"
    },
    "id": "d1cb39e5"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'review_id': pd.read_csv('../input/headhunter/data/data/test.csv', index_col='review_id').index, \n",
    "    'target': pred_labels\n",
    "}).to_csv('answers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T12:58:27.957968Z",
     "iopub.status.busy": "2022-02-19T12:58:27.957752Z",
     "iopub.status.idle": "2022-02-19T13:01:34.598016Z",
     "shell.execute_reply": "2022-02-19T13:01:34.597142Z",
     "shell.execute_reply.started": "2022-02-19T12:58:27.957940Z"
    },
    "id": "Jmhxa-Xobnag"
   },
   "outputs": [],
   "source": [
    "dataloader_test = DataLoader(dataset_test, batch_size=64, shuffle=False)\n",
    "\n",
    "embeddings_test = []\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(dataloader_test):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        embeddings_test.append(model(**batch, \n",
    "                                     output_hidden_states=True)['hidden_states'][0].mean(dim=1).cpu())\n",
    "\n",
    "embeddings_test = np.concatenate(embeddings_test, axis=0)\n",
    "embeddings_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T13:01:34.600087Z",
     "iopub.status.busy": "2022-02-19T13:01:34.599420Z",
     "iopub.status.idle": "2022-02-19T13:04:40.139028Z",
     "shell.execute_reply": "2022-02-19T13:04:40.138276Z",
     "shell.execute_reply.started": "2022-02-19T13:01:34.600042Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(dataset_train, batch_size=64, shuffle=False)\n",
    "\n",
    "embeddings_train = []\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(dataloader_train):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        embeddings_train.append(model(**batch, \n",
    "                                      output_hidden_states=True)['hidden_states'][0].mean(dim=1).cpu())\n",
    "\n",
    "embeddings_train = np.concatenate(embeddings_train, axis=0)\n",
    "embeddings_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T13:14:15.471421Z",
     "iopub.status.busy": "2022-02-19T13:14:15.470710Z",
     "iopub.status.idle": "2022-02-19T13:14:23.586056Z",
     "shell.execute_reply": "2022-02-19T13:14:23.585156Z",
     "shell.execute_reply.started": "2022-02-19T13:14:15.471338Z"
    }
   },
   "outputs": [],
   "source": [
    "Xy_train_val = pd.read_csv('../input/headhunter/data/data/train.csv', index_col='review_id').fillna('Нет информации.')\n",
    "X_train_val, y_train_val = Xy_train_val.iloc[:, :-1], Xy_train_val.iloc[:, -1]\n",
    "\n",
    "mb = MultiLabelBinarizer(classes=[str(i) for i in range(9)])\n",
    "y_train_val = mb.fit_transform(y_train_val)\n",
    "\n",
    "X_test = pd.read_csv('../input/headhunter/data/data/test.csv', index_col='review_id').fillna('Нет информации.')\n",
    "\n",
    "for data in [X_train_val, X_test]:\n",
    "    \n",
    "    # class 0: special symbol\n",
    "    data['xa_symbol_pos'] = (data['positive'].str.find('\\xa0') != -1).astype(int)\n",
    "    data['xa_symbol_neg'] = (data['negative'].str.find('\\xa0') != -1).astype(int)\n",
    "    \n",
    "    # small preprocessing\n",
    "    data['positive'] = data['positive'].str.replace(',', ', ').str.replace('.', '. ').apply(lambda x: re.sub(' +', ' ', x))\n",
    "    data['negative'] = data['negative'].str.replace(',', ', ').str.replace('.', '. ').apply(lambda x: re.sub(' +', ' ', x))\n",
    "    \n",
    "    # class 8: length (with round -1)\n",
    "    data['length_pos'] = data['positive'].apply(lambda x: round(len(x), -1)) # .str.len() also works\n",
    "    data.loc[data['length_pos'] > 1000, 'length_pos'] = 1000\n",
    "    data['length_neg'] = data['negative'].apply(lambda x: round(len(x), -1))\n",
    "    data.loc[data['length_neg'] > 1000, 'length_neg'] = 1000\n",
    "    \n",
    "    # class \n",
    "    data['max_pos'] = data['positive'].apply(lambda x: np.max([len(w) for w in x.split(' ')]))\n",
    "    data.loc[data['max_pos'] > 25, 'max_pos'] = 25\n",
    "    data['max_neg'] = data['negative'].apply(lambda x: np.max([len(w) for w in x.split(' ')]))\n",
    "    data.loc[data['max_neg'] > 25, 'max_neg'] = 25\n",
    "    \n",
    "    #\n",
    "    data['most_common_pos'] = data['positive'].apply(\n",
    "        lambda x: Counter([w for w in x.split(' ')]).most_common(1)[0][1]\n",
    "    )\n",
    "    data.loc[data['most_common_pos'] > 25, 'most_common_pos'] = 25\n",
    "    data['most_common_neg'] = data['negative'].apply(\n",
    "        lambda x: Counter([w for w in x.split(' ')]).most_common(1)[0][1]\n",
    "    )\n",
    "    data.loc[data['most_common_neg'] > 25, 'most_common_neg'] = 25\n",
    "    \n",
    "    for col in ['city', 'position']:\n",
    "        counts = data[col].value_counts()\n",
    "        data.loc[data[col].isin(counts[counts < 10].index), col] = 'Прочее'\n",
    "        \n",
    "    cols = ['salary_rating', 'team_rating', 'managment_rating', \n",
    "            'career_rating', 'workplace_rating', 'rest_recovery_rating']\n",
    "    \n",
    "    for i in range(1, 5+1):\n",
    "        data[f'count_{i}'] = (data.loc[:, cols] == i).sum(axis=1)\n",
    "    \n",
    "    data['rating_mean'] = data.loc[:, cols].mean(axis=1)\n",
    "    data['rating_std'] = data.loc[:, cols].std(axis=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, \n",
    "                                                  test_size=0.01, random_state=42)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T13:14:23.588780Z",
     "iopub.status.busy": "2022-02-19T13:14:23.588258Z",
     "iopub.status.idle": "2022-02-19T13:14:23.594976Z",
     "shell.execute_reply": "2022-02-19T13:14:23.594104Z",
     "shell.execute_reply.started": "2022-02-19T13:14:23.588738Z"
    }
   },
   "outputs": [],
   "source": [
    "class DummyTransformer(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Mini class to return initial features without transformation\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, value=None):\n",
    "        TransformerMixin.__init__(self)\n",
    "        self.value = value\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {'value': self.value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T13:14:23.596195Z",
     "iopub.status.busy": "2022-02-19T13:14:23.595983Z",
     "iopub.status.idle": "2022-02-19T13:14:24.312913Z",
     "shell.execute_reply": "2022-02-19T13:14:24.312216Z",
     "shell.execute_reply.started": "2022-02-19T13:14:23.596169Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train.reset_index(drop=True), \n",
    "                     pd.DataFrame(embeddings_train).reset_index(drop=True)], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), \n",
    "                    pd.DataFrame(embeddings_test).reset_index(drop=True)], axis=1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T13:14:57.156249Z",
     "iopub.status.busy": "2022-02-19T13:14:57.155740Z",
     "iopub.status.idle": "2022-02-19T13:56:39.568964Z",
     "shell.execute_reply": "2022-02-19T13:56:39.568132Z",
     "shell.execute_reply.started": "2022-02-19T13:14:57.156206Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('transforms', ColumnTransformer([\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore'), [0, 1] + [*range(4, X_train.shape[1]-2-768)]),\n",
    "        ('features', DummyTransformer(), [*range(X_train.shape[1]-2-768, X_train.shape[1])])\n",
    "    ])),\n",
    "    ('lr', OneVsRestClassifier(LogisticRegression(C=0.1, max_iter=500, n_jobs=-1, random_state=42)))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T13:56:39.571976Z",
     "iopub.status.busy": "2022-02-19T13:56:39.571194Z",
     "iopub.status.idle": "2022-02-19T13:56:39.579232Z",
     "shell.execute_reply": "2022-02-19T13:56:39.578572Z",
     "shell.execute_reply.started": "2022-02-19T13:56:39.571927Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_multilabel(model, X):\n",
    "    y_pred = list(map(lambda x: ','.join(x), mb.inverse_transform(model.predict(X))))\n",
    "    y_pred_top1 = model.predict_proba(X).argmax(axis=1)\n",
    "    \n",
    "    return np.where([len(x) > 0 for x in y_pred], y_pred, y_pred_top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T13:57:30.296455Z",
     "iopub.status.busy": "2022-02-19T13:57:30.295820Z",
     "iopub.status.idle": "2022-02-19T13:57:35.851271Z",
     "shell.execute_reply": "2022-02-19T13:57:35.850522Z",
     "shell.execute_reply.started": "2022-02-19T13:57:30.296408Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'review_id': pd.read_csv('../input/headhunter/data/data/test.csv', index_col='review_id').index, \n",
    "    'target': predict_multilabel(pipeline, X_test) # model.predict(X_test).flatten()\n",
    "}).to_csv('answers1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
